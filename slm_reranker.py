import ollama # Standard for running local SLMs like Phi or Llama 3 8B [1]

def slm_re_ranker(query, retrieved_documents):
    """
    Uses a local SLM (Phi-3) to re-rank documents for cost/latency optimization [1].
    """
    ranked_results = []
    
    # We iterate through the documents retrieved by your RAG pipeline
    for doc in retrieved_documents:
        # Prompting the SLM to act as a relevance judge
        prompt = f"""
        Task: Rate the relevance of the following document to the user query.
        Query: {query}
        Document: {doc.page_content}
        
        Return only a numerical score between 0 and 10, where 10 is highly relevant.
        Score:"""
        
        # Calling the local SLM (e.g., Phi-3 or Llama3-8b)
        response = ollama.generate(model='llama3.2:3b', prompt=prompt)
        
        try:
            score = float(response['response'].strip())
            ranked_results.append((score, doc))
        except ValueError:
            # Fallback for inconsistent SLM output formats
            ranked_results.append((0, doc))

    # Sort documents by the score assigned by the SLM (highest first)
    ranked_results.sort(key=lambda x: x[0], reverse=True)
    
    # Return only the top-ranked documents to the final synthesis agent [1]
    return [doc for score, doc in ranked_results[:3]]

def deduplicate_results(results_list):
    seen_ids = set()
    unique_documents = []

    # Iterate through the nested lists generated by your multiple queries
    for sublist in results_list:
        for doc in sublist:
            # Check for a unique identifier (metadata ID or content hash)
            doc_id = doc.metadata.get('id') or hash(doc.page_content)
            
            if doc_id not in seen_ids:
                unique_documents.append(doc)
                seen_ids.add(doc_id)
                
    return unique_documents